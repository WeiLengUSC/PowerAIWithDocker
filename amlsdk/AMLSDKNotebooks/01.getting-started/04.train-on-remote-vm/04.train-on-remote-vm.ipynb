{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright (c) Microsoft Corporation. All rights reserved.\n",
    "\n",
    "Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 04. Train in a remote Linux VM\n",
    "* Create Workspace\n",
    "* Create `train.py` file\n",
    "* Create (or attach) DSVM as compute resource.\n",
    "* Upoad data files into default datastore\n",
    "* Configure & execute a run in a few different ways\n",
    "    - Use system-built conda\n",
    "    - Use existing Python environment\n",
    "    - Use Docker \n",
    "* Find the best model in the run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites\n",
    "Make sure you go through the [00. Installation and Configuration](00.configuration.ipynb) Notebook first if you haven't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Allow multiple displays per cell\n",
    "from IPython.core.interactiveshell import InteractiveShell\n",
    "InteractiveShell.ast_node_interactivity = \"all\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SDK version: 0.1.74\n"
     ]
    }
   ],
   "source": [
    "# Check core SDK version number\n",
    "import azureml.core\n",
    "\n",
    "print(\"SDK version:\", azureml.core.VERSION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Workspace\n",
    "\n",
    "Initialize a workspace object from persisted configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found the config file in: /workspace/amlsdk/AMLSDKNotebooks/aml_config/config.json\n",
      "ghiordanDockerPower001ws\n",
      "ghiordanDockerPower001rsg\n",
      "e\n",
      "e\n"
     ]
    }
   ],
   "source": [
    "from azureml.core import Workspace\n",
    "\n",
    "ws = Workspace.from_config()\n",
    "print(ws.name, ws.resource_group, ws.location[:1], ws.subscription_id[:1], sep='\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Experiment\n",
    "\n",
    "**Experiment** is a logical container in an Azure ML Workspace. It hosts run records which can include run metrics and output artifacts from your experiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'train-on-remote-vm'\n",
    "\n",
    "from azureml.core import Experiment\n",
    "exp = Experiment(workspace=ws, name=experiment_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also create a local folder to hold the training script."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "script_folder = './vm-run'\n",
    "os.makedirs(script_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Upload data files into datastore\n",
    "Every workspace comes with a default datastore (and you can register more) which is backed by the Azure blob storage account associated with the workspace. We can use it to transfer data from local to the cloud, and access it from the compute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "workspacefilestore AzureFile gh az\n"
     ]
    }
   ],
   "source": [
    "# get the default datastore\n",
    "ds = ws.get_default_datastore()\n",
    "print(ds.name, ds.datastore_type, ds.account_name[:2], ds.container_name[:2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load diabetes data from `scikit-learn` and save it as 2 local files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_diabetes\n",
    "import numpy as np\n",
    "\n",
    "training_data = load_diabetes()\n",
    "np.save(file='./features.npy', arr=training_data['data'])\n",
    "np.save(file='./labels.npy', arr=training_data['target'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now let's upload the 2 files into the default datastore under a path named `diabetes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$AZUREML_DATAREFERENCE_4123d49f0c3842efbaf2c11c4047dd53"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.upload_files(['./features.npy', './labels.npy'], target_path='diabetes', overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View `train.py`\n",
    "\n",
    "For convenience, we created a training script for you. It is printed below as a text, but you can also run `%pfile ./train.py` in a cell to show the file. Please pay special attention on how we are loading the features and labels from files in the `data_folder` path, which is passed in as an argument of the training script (shown later)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./vm-run/train.py'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# Copyright (c) Microsoft. All rights reserved.\n",
      "# Licensed under the MIT license.\n",
      "\n",
      "import os\n",
      "import argparse\n",
      "\n",
      "from sklearn.linear_model import Ridge\n",
      "from sklearn.metrics import mean_squared_error\n",
      "from sklearn.model_selection import train_test_split\n",
      "from azureml.core.run import Run\n",
      "from sklearn.externals import joblib\n",
      "\n",
      "import numpy as np\n",
      "\n",
      "os.makedirs('./outputs', exist_ok=True)\n",
      "parser = argparse.ArgumentParser()\n",
      "parser.add_argument('--data-folder', type=str,\n",
      "                    dest='data_folder', help='data folder')\n",
      "args = parser.parse_args()\n",
      "\n",
      "print('Data folder is at:', args.data_folder)\n",
      "print('List all files: ', os.listdir(args.data_folder))\n",
      "\n",
      "X = np.load(os.path.join(args.data_folder, 'features.npy'))\n",
      "y = np.load(os.path.join(args.data_folder, 'labels.npy'))\n",
      "\n",
      "run = Run.get_context()\n",
      "\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    X, y, test_size=0.2, random_state=0)\n",
      "data = {\"train\": {\"X\": X_train, \"y\": y_train},\n",
      "        \"test\": {\"X\": X_test, \"y\": y_test}}\n",
      "\n",
      "# list of numbers from 0.0 to 1.0 with a 0.05 interval\n",
      "alphas = np.arange(0.0, 1.0, 0.05)\n",
      "\n",
      "for alpha in alphas:\n",
      "    # Use Ridge algorithm to create a regression model\n",
      "    reg = Ridge(alpha=alpha)\n",
      "    reg.fit(data[\"train\"][\"X\"], data[\"train\"][\"y\"])\n",
      "\n",
      "    preds = reg.predict(data[\"test\"][\"X\"])\n",
      "    mse = mean_squared_error(preds, data[\"test\"][\"y\"])\n",
      "    run.log('alpha', alpha)\n",
      "    run.log('mse', mse)\n",
      "\n",
      "    model_file_name = 'ridge_{0:.2f}.pkl'.format(alpha)\n",
      "    with open(model_file_name, \"wb\") as file:\n",
      "        joblib.dump(value=reg, filename='outputs/' + model_file_name)\n",
      "\n",
      "    print('alpha is {0:.2f}, and mse is {1:0.2f}'.format(alpha, mse))\n"
     ]
    }
   ],
   "source": [
    "# copy train.py into the script folder\n",
    "import shutil\n",
    "shutil.copy('./train.py', os.path.join(script_folder, 'train.py'))\n",
    "\n",
    "with open(os.path.join(script_folder, './train.py'), 'r') as training_script:\n",
    "    print(training_script.read())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Linux DSVM as a compute target\n",
    "\n",
    "**Note**: If creation fails with a message about Marketplace purchase eligibilty, go to portal.azure.com, start creating DSVM there, and select \"Want to create programmatically\" to enable programmatic creation. Once you've enabled it, you can exit without actually creating VM.\n",
    " \n",
    "**Note**: By default SSH runs on port 22 and you don't need to specify it. But if for security reasons you switch to a different port (such as 5022), you can specify the port number in the provisioning configuration object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_target_name = 'ghiordanXRgpuvm'\n",
    "\n",
    "if False:\n",
    "    from azureml.core.compute import DsvmCompute\n",
    "    from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "    try:\n",
    "        dsvm_compute = DsvmCompute(workspace=ws, name=compute_target_name)\n",
    "        print('found existing:', dsvm_compute.name)\n",
    "    except ComputeTargetException:\n",
    "        print('creating new.')\n",
    "        dsvm_config = DsvmCompute.provisioning_configuration(vm_size=\"Standard_D2_v2\")\n",
    "        dsvm_compute = DsvmCompute.create(ws, name=compute_target_name, provisioning_configuration=dsvm_config)\n",
    "        dsvm_compute.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Attach an existing Linux DSVM\n",
    "You can also attach an existing Linux VM as a compute target. The default port is 22."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SucceededProvisioning operation finished, operation \"Succeeded\"\n"
     ]
    }
   ],
   "source": [
    "%dotenv\n",
    "\n",
    "from azureml.core.compute import RemoteCompute \n",
    "# if you want to connect using SSH key instead of username/password you can provide parameters private_key_file and private_key_passphrase \n",
    "attached_dsvm_compute = RemoteCompute.attach(workspace=ws,\n",
    "                                             name='ghiordanXRgpuvm',\n",
    "                                             username=os.getenv('COMPUTE_CONTEXT_VM_USER_NAME'),\n",
    "                                             address=os.getenv('COMPUTE_CONTEXT_VM_FQDN'),\n",
    "                                             ssh_port=os.getenv('COMPUTE_CONTEXT_VM_SSH_PORT'),\n",
    "                                             password=os.getenv('COMPUTE_CONTEXT_VM_PWD'))\n",
    "attached_dsvm_compute.wait_for_completion(show_output=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure & Run\n",
    "First let's create a `DataReferenceConfiguration` object to inform the system what data folder to download to the copmute target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.runconfig import DataReferenceConfiguration\n",
    "dr = DataReferenceConfiguration(datastore_name=ds.name, \n",
    "                   path_on_datastore='diabetes', \n",
    "                   mode='download', # download files from datastore to compute target\n",
    "                   overwrite=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can try a few different ways to run the training script in the VM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configure a Docker run with new conda environment on the VM\n",
    "You can execute in a Docker container in the VM. If you choose this option, the system will pull down a base Docker image, build a new conda environment in it if you ask for (you can also skip this if you are using a customer Docker image when a preconfigured Python environment), start a container, and run your script in there. This image is also uploaded into your ACR (Azure Container Registry) assoicated with your workspace, an reused if your dependencies don't change in the subsequent runs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Base Docker image is: mcr.microsoft.com/azureml/base:0.1.4\n"
     ]
    }
   ],
   "source": [
    "from azureml.core.runconfig import RunConfiguration\n",
    "from azureml.core.conda_dependencies import CondaDependencies\n",
    "\n",
    "\n",
    "# Load the \"cpu-dsvm.runconfig\" file (created by the above attach operation) in memory\n",
    "docker_run_config = RunConfiguration(framework=\"python\")\n",
    "\n",
    "# Set compute target to the Linux DSVM\n",
    "docker_run_config.target = compute_target_name\n",
    "\n",
    "# Use Docker in the remote VM\n",
    "docker_run_config.environment.docker.enabled = True\n",
    "\n",
    "# Use CPU base image from DockerHub\n",
    "docker_run_config.environment.docker.base_image = azureml.core.runconfig.DEFAULT_CPU_IMAGE\n",
    "print('Base Docker image is:', docker_run_config.environment.docker.base_image)\n",
    "\n",
    "# set the data reference of the run coonfiguration\n",
    "docker_run_config.data_references = {ds.name: dr}\n",
    "\n",
    "# specify CondaDependencies obj\n",
    "docker_run_config.environment.python.conda_dependencies = CondaDependencies.create(conda_packages=['scikit-learn'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit the Experiment\n",
    "Submit script to run in the Docker image in the remote VM. If you run this for the first time, the system will download the base image, layer in packages specified in the `conda_dependencies.yml` file on top of the base image, create a container and then execute the script in the container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import ScriptRunConfig\n",
    "src = ScriptRunConfig(source_directory=script_folder, \n",
    "                      script='train.py', \n",
    "                      run_config=docker_run_config,\n",
    "                      # pass the datastore reference as a parameter to the training script\n",
    "                      arguments=['--data-folder', str(ds.as_download())])\n",
    "run = exp.submit(config=src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "run.wait_for_completion(show_output=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View run history details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table style=\"width:100%\"><tr><th>Experiment</th><th>Id</th><th>Type</th><th>Status</th><th>Details Page</th><th>Docs Page</th></tr><tr><td>train-on-remote-vm</td><td>train-on-remote-vm_1541973343165</td><td>azureml.scriptrun</td><td>Finalizing</td><td><a href=\"https://mlworkspace.azure.ai/portal/subscriptions/edf507a2-6235-46c5-b560-fd463ba2e771/resourceGroups/ghiordanDockerPower001rsg/providers/Microsoft.MachineLearningServices/workspaces/ghiordanDockerPower001ws/experiments/train-on-remote-vm/runs/train-on-remote-vm_1541973343165\" target=\"_blank\" rel=\"noopener\">Link to Azure Portal</a></td><td><a href=\"https://docs.microsoft.com/en-us/python/api/azureml-core/azureml.core.script_run.ScriptRun?view=azure-ml-py\" target=\"_blank\" rel=\"noopener\">Link to Documentation</a></td></tr></table>"
      ],
      "text/plain": [
       "Run(Experiment: train-on-remote-vm,\n",
       "Id: train-on-remote-vm_1541973343165,\n",
       "Type: azureml.scriptrun,\n",
       "Status: Finalizing)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the best model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have tried various execution modes, we can find the best model from the last run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': [0.0,\n",
       "  0.05,\n",
       "  0.1,\n",
       "  0.15000000000000002,\n",
       "  0.2,\n",
       "  0.25,\n",
       "  0.30000000000000004,\n",
       "  0.35000000000000003,\n",
       "  0.4,\n",
       "  0.45,\n",
       "  0.5,\n",
       "  0.55,\n",
       "  0.6000000000000001,\n",
       "  0.65,\n",
       "  0.7000000000000001,\n",
       "  0.75,\n",
       "  0.8,\n",
       "  0.8500000000000001,\n",
       "  0.9,\n",
       "  0.9500000000000001],\n",
       " 'mse': [3424.316688213733,\n",
       "  3408.91531225893,\n",
       "  3372.6496278100326,\n",
       "  3345.1496434741894,\n",
       "  3325.294679467877,\n",
       "  3311.556250928974,\n",
       "  3302.673633401725,\n",
       "  3297.6587339442026,\n",
       "  3295.741064355809,\n",
       "  3296.316884705675,\n",
       "  3298.909605807062,\n",
       "  3303.1400555275163,\n",
       "  3308.7042707723226,\n",
       "  3315.3568399622563,\n",
       "  3322.8983149039614,\n",
       "  3331.1656169285875,\n",
       "  3340.0246620321604,\n",
       "  3349.3646443486023,\n",
       "  3359.0935697484424,\n",
       "  3369.1347399130477]}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get all metris logged in the run\n",
    "run.get_metrics()\n",
    "metrics = run.get_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "When alpha is 0.40, we have min MSE 3295.74.\n"
     ]
    }
   ],
   "source": [
    "# find the index where MSE is the smallest\n",
    "indices = list(range(0, len(metrics['mse'])))\n",
    "min_mse_index = min(indices, key=lambda x: metrics['mse'][x])\n",
    "\n",
    "print('When alpha is {1:0.2f}, we have min MSE {0:0.2f}.'.format(\n",
    "    metrics['mse'][min_mse_index], \n",
    "    metrics['alpha'][min_mse_index]\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['azureml-logs/60_control_log.txt',\n",
       " 'azureml-logs/80_driver_log.txt',\n",
       " 'outputs/ridge_0.75.pkl',\n",
       " 'outputs/ridge_0.35.pkl',\n",
       " 'outputs/ridge_0.05.pkl',\n",
       " 'outputs/ridge_0.15.pkl',\n",
       " 'outputs/ridge_0.45.pkl',\n",
       " 'outputs/ridge_0.30.pkl',\n",
       " 'outputs/ridge_0.10.pkl',\n",
       " 'outputs/ridge_0.95.pkl',\n",
       " 'outputs/ridge_0.40.pkl',\n",
       " 'outputs/ridge_0.80.pkl',\n",
       " 'outputs/ridge_0.90.pkl',\n",
       " 'outputs/ridge_0.20.pkl',\n",
       " 'outputs/ridge_0.25.pkl',\n",
       " 'outputs/ridge_0.55.pkl',\n",
       " 'outputs/ridge_0.65.pkl',\n",
       " 'outputs/ridge_0.85.pkl',\n",
       " 'outputs/ridge_0.00.pkl',\n",
       " 'outputs/ridge_0.60.pkl',\n",
       " 'outputs/ridge_0.70.pkl',\n",
       " 'outputs/ridge_0.50.pkl',\n",
       " 'driver_log',\n",
       " 'azureml-logs/azureml.log']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.get_file_names()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We know the model ridge_0.40.pkl is the best performing model from the eariler queries. \n",
    "So we can register it with the workspace, or download locally"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# supply a model name, and the full path to the serialized model file.\n",
    "model = run.register_model(model_name='second_best_ridge_model', model_path='./outputs/ridge_0.10.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'./../../ridge_0.40.pkl'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from azureml.core.model import Model\n",
    "\n",
    "model_local_file_path = os.path.join(*(['.', '..', '..']+['ridge_0.40.pkl'])) \n",
    "model_local_file_path\n",
    "run.download_file(name='./outputs/ridge_0.40.pkl', output_file_path=model_local_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 304\r\n",
      "-rw-r--r-- 1 root root 276011 Nov 11 19:22 00.configuration.html\r\n",
      "-rw-rw-r-- 1 1003 1003  14968 Nov 11 20:06 00.configuration.ipynb\r\n",
      "drwxrwxr-x 3 1003 1003   4096 Nov 11 21:49 01.getting-started\r\n",
      "drwxrwxr-x 3 1003 1003   4096 Nov 11 21:14 10.register-model-create-image-deploy-service\r\n",
      "drwxr-xr-x 2 root root   4096 Nov 10 01:29 aml_config\r\n",
      "-rw-r--r-- 1 root root    658 Nov 11 21:55 ridge_0.40.pkl\r\n"
     ]
    }
   ],
   "source": [
    "# show ridge_0.40.pkl exists locally\n",
    "!ls -l ./../../"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "authors": [
   {
    "name": "haining"
   }
  ],
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
